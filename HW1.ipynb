{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Обратный индекс \n",
    "\n",
    "Сам по себе обратный индекс не может осуществлять поиск, для этого необходимо добавить к нему определенную метрику. Это не совсем очевидная задача, поэтому немного отложим ее. А сейчас посмотрим, что полезного можно вытащить из индекса.    \n",
    "По сути, индекс - это информация о частоте встречаемости слова в каждом документе.   \n",
    "Из этого можно понять, например:\n",
    "1. какое слово является самым часто употребимым / редким\n",
    "2. какие слова встречаются всегда вместе. Так можно парсить твиттер, fb, форумы и отлавливать новые устойчивые выражения в речи\n",
    "3. какой документ является самым большим / маленьким (очень изощренный способ, когда есть _len_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача__: \n",
    "получите обратный индекс для коллекция документов.    \n",
    "Перед этим постройте матрицу терм-документ и сделайте функцию булева поиска, которая по запросу будет возвращать 5 релевантных документов.   \n",
    "В качестве коллекции возьмите сценарий сезонов сериала Друзья. Одна серия - один документ.\n",
    "\n",
    "[download_friends_corpus](https://yadi.sk/d/k_M7n63A3adGSz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этапы:   \n",
    "    1. получить коллекцию документов\n",
    "    2. для каждого файла коллекции сделать необходимую на ваш взгляд предобработку\n",
    "    3. получить матрицу терм-документ, написать функцию поиска по ней\n",
    "    4. получить обратный индекс в виде словаря, где ключ - нормализованное слово, \n",
    "    значение - список файлов, в которых это слово встречается\n",
    "    5. вывести кусочек индекса в виде таблицы \n",
    "    6. сделать анализ обратного индекса. Это задание принимается в виде кода и ответов на вопросы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Friends/wedding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напоминание:    \n",
    "> При итерации по списку вы можете помимо самого элемента получить его порядковый номер    \n",
    "``` for i, element in enumerate(your_list): ...  ```    \n",
    "Иногда для получения элемента делают так -  ``` your_list[i] ```, старайтесь этого избегать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/inv_index3.svg\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совет для построения обратного индекса: \n",
    "> В качестве словаря используйте ``` defaultdict ``` из модуля collections   \n",
    "Так можно избежать конструкции ``` dict.setdefault(key, default=None) ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pymystem3 import Mystem\n",
    "mystem = Mystem()\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(input_text, del_stopwords=True, del_digit=True):\n",
    "    \"\"\"\n",
    "    :input: raw text\n",
    "    1. lowercase, del punctuation, tokenize\n",
    "    2. normal form\n",
    "    3. del stopwords\n",
    "    4. del digits\n",
    "    :return: lemmas\n",
    "    \"\"\"\n",
    "    russian_stopwords = set(stopwords.words('russian'))\n",
    "    words = [x.lower().strip(punctuation+'»«–…') for x in word_tokenize(input_text)]\n",
    "    lemmas = [mystem.lemmatize(x)[0] for x in words if x]\n",
    "\n",
    "    lemmas_arr = []\n",
    "    for lemma in lemmas:\n",
    "        if del_stopwords:\n",
    "            if lemma in russian_stopwords:\n",
    "                continue\n",
    "        if del_digit:\n",
    "            if lemma.isdigit():\n",
    "                continue\n",
    "        lemmas_arr.append(lemma)\n",
    "    return lemmas_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inverted_index(files_list):\n",
    "    \"\"\"\n",
    "    Create inverted index by input doc collection\n",
    "    :return: inverted index\n",
    "    \"\"\"\n",
    "    global main_dir\n",
    "    index = {}\n",
    "    files_len = {}\n",
    "    for file in files_list:\n",
    "        with open(main_dir +'/'+ file, 'r', encoding='utf-8') as f:\n",
    "            words = preprocessing(f.read())\n",
    "            files_len[file] = len(words)\n",
    "            counter = Counter(words)\n",
    "            for word in counter:\n",
    "                if word in index:\n",
    "                    index[word][file] = counter[word]\n",
    "                else:\n",
    "                    index[word] = {}\n",
    "                    index[word][file] = counter[word]\n",
    "    return files_len, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_len, index = inverted_index(files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.25</th>\n",
       "      <th>1.5</th>\n",
       "      <th>1.75</th>\n",
       "      <th>11б</th>\n",
       "      <th>12.50</th>\n",
       "      <th>12.75</th>\n",
       "      <th>1986ом</th>\n",
       "      <th>1999ый</th>\n",
       "      <th>2.75</th>\n",
       "      <th>20й</th>\n",
       "      <th>...</th>\n",
       "      <th>ясность</th>\n",
       "      <th>ясный</th>\n",
       "      <th>яхта</th>\n",
       "      <th>ящерица</th>\n",
       "      <th>ящик</th>\n",
       "      <th>ящичек</th>\n",
       "      <th>—</th>\n",
       "      <th>№</th>\n",
       "      <th>﻿</th>\n",
       "      <th>﻿</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Friends - 1x01 - The One Where Monica Gets A Roommate.ru.txt</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Friends - 1x02 - The One With The Sonogram At The End.ru.txt</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Friends - 1x03 - The One With The Thumb.ru.txt</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Friends - 1x04 - The One With George Stephanopoulos.ru.txt</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Friends - 1x05 - The One With The East German Laundry Detergent.ru.txt</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 14042 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    1.25  1.5  1.75  11б  \\\n",
       "Friends - 1x01 - The One Where Monica Gets A Ro...   NaN  NaN   NaN  NaN   \n",
       "Friends - 1x02 - The One With The Sonogram At T...   NaN  NaN   NaN  NaN   \n",
       "Friends - 1x03 - The One With The Thumb.ru.txt       NaN  NaN   NaN  NaN   \n",
       "Friends - 1x04 - The One With George Stephanopo...   NaN  NaN   NaN  NaN   \n",
       "Friends - 1x05 - The One With The East German L...   NaN  NaN   NaN  NaN   \n",
       "\n",
       "                                                    12.50  12.75  1986ом  \\\n",
       "Friends - 1x01 - The One Where Monica Gets A Ro...    NaN    NaN     NaN   \n",
       "Friends - 1x02 - The One With The Sonogram At T...    NaN    NaN     NaN   \n",
       "Friends - 1x03 - The One With The Thumb.ru.txt        NaN    NaN     NaN   \n",
       "Friends - 1x04 - The One With George Stephanopo...    NaN    NaN     NaN   \n",
       "Friends - 1x05 - The One With The East German L...    NaN    NaN     NaN   \n",
       "\n",
       "                                                    1999ый  2.75  20й ...   \\\n",
       "Friends - 1x01 - The One Where Monica Gets A Ro...     NaN   NaN  NaN ...    \n",
       "Friends - 1x02 - The One With The Sonogram At T...     NaN   NaN  NaN ...    \n",
       "Friends - 1x03 - The One With The Thumb.ru.txt         NaN   NaN  NaN ...    \n",
       "Friends - 1x04 - The One With George Stephanopo...     NaN   NaN  NaN ...    \n",
       "Friends - 1x05 - The One With The East German L...     NaN   NaN  NaN ...    \n",
       "\n",
       "                                                    ясность  ясный  яхта  \\\n",
       "Friends - 1x01 - The One Where Monica Gets A Ro...      NaN    NaN   NaN   \n",
       "Friends - 1x02 - The One With The Sonogram At T...      NaN    NaN   NaN   \n",
       "Friends - 1x03 - The One With The Thumb.ru.txt          NaN    NaN   NaN   \n",
       "Friends - 1x04 - The One With George Stephanopo...      NaN    NaN   NaN   \n",
       "Friends - 1x05 - The One With The East German L...      NaN    NaN   NaN   \n",
       "\n",
       "                                                    ящерица  ящик  ящичек  \\\n",
       "Friends - 1x01 - The One Where Monica Gets A Ro...      1.0   NaN     NaN   \n",
       "Friends - 1x02 - The One With The Sonogram At T...      NaN   NaN     NaN   \n",
       "Friends - 1x03 - The One With The Thumb.ru.txt          NaN   NaN     NaN   \n",
       "Friends - 1x04 - The One With George Stephanopo...      NaN   NaN     NaN   \n",
       "Friends - 1x05 - The One With The East German L...      NaN   NaN     NaN   \n",
       "\n",
       "                                                     —\\n   №    ﻿  ﻿\\n  \n",
       "Friends - 1x01 - The One Where Monica Gets A Ro...  16.0 NaN  1.0  NaN  \n",
       "Friends - 1x02 - The One With The Sonogram At T...   NaN NaN  1.0  NaN  \n",
       "Friends - 1x03 - The One With The Thumb.ru.txt       NaN NaN  NaN  1.0  \n",
       "Friends - 1x04 - The One With George Stephanopo...   NaN NaN  1.0  NaN  \n",
       "Friends - 1x05 - The One With The East German L...   NaN NaN  1.0  NaN  \n",
       "\n",
       "[5 rows x 14042 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(index).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью обратного индекса произведите следующую аналитику:  \n",
    "\n",
    "1) общая аналитика\n",
    "- какое слово является самым частотным?\n",
    "- какое самым редким?\n",
    "- какой набор слов есть во всех документах коллекции?\n",
    "\n",
    "2) частота встречаемости имен главных героев в каждом сезоне      \n",
    "- какой сезон был самым популярным у Чендлера? у Моники?   \n",
    "- кто из главных героев статистически самый популярный? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7517, 'это'],\n",
       " [2660, 'знать'],\n",
       " [2025, 'хотеть'],\n",
       " [1902, 'мочь'],\n",
       " [1542, 'сказать'],\n",
       " [1289, 'думать'],\n",
       " [1244, 'просто'],\n",
       " [1111, 'ладно'],\n",
       " [1071, 'давать'],\n",
       " [1035, 'твой']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = []\n",
    "for word in index:\n",
    "    freq.append([sum(index[word].values()), word])\n",
    "sorted(freq, reverse = True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самое частотное слово - это слово 'это'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'tяжелый'],\n",
       " [1, 'vanilla'],\n",
       " [1, 've'],\n",
       " [1, 'wan'],\n",
       " [1, 'was'],\n",
       " [1, 'we'],\n",
       " [1, 'were'],\n",
       " [1, 'whole'],\n",
       " [1, 'will'],\n",
       " [1, 'wish'],\n",
       " [1, 'with'],\n",
       " [1, 'wondering'],\n",
       " [1, 'wоw'],\n",
       " [1, 'xvid'],\n",
       " [1, 'yell'],\n",
       " [1, 'your'],\n",
       " [1, 'z'],\n",
       " [1, 'ааааааа'],\n",
       " [1, 'аааааау'],\n",
       " [1, 'ааааах'],\n",
       " [1, 'абонемент'],\n",
       " [1, 'абрикос'],\n",
       " [1, 'абсурд'],\n",
       " [1, 'абсурдный'],\n",
       " [1, 'абы'],\n",
       " [1, 'аварийный'],\n",
       " [1, 'авиа'],\n",
       " [1, 'авиамодельный'],\n",
       " [1, 'авианосец'],\n",
       " [1, 'авиапочта'],\n",
       " [1, 'австралийский'],\n",
       " [1, 'австралия'],\n",
       " [1, 'авто'],\n",
       " [1, 'автобизнес'],\n",
       " [1, 'автобусный'],\n",
       " [1, 'автомобиль'],\n",
       " [1, 'авторство'],\n",
       " [1, 'автостопом'],\n",
       " [1, 'агамемнон'],\n",
       " [1, 'агрегат'],\n",
       " [1, 'ада'],\n",
       " [1, 'адвокатский'],\n",
       " [1, 'аделаида'],\n",
       " [1, 'адидас'],\n",
       " [1, 'адно'],\n",
       " [1, 'адресат'],\n",
       " [1, 'адресовать'],\n",
       " [1, 'адский'],\n",
       " [1, 'азарт'],\n",
       " [1, 'азартный']]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(freq)[150:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если говорить о самых редких РУССКИХ словах, то это будут слова абонемент, абрикос, абсурд - и. т.д., все они одинаково редки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['просто', 'знать', 'хотеть', 'это', 'сказать', 'думать']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs = []\n",
    "for word in index:\n",
    "    if len(index[word].values()) == 165:\n",
    "        all_docs.append(word)\n",
    "\n",
    "all_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такой набор слов был во всех документах коллекции (не считая стоп-слова, которые мы выкинули, я думаю, они также встречались во всех документах)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fr_ch = {1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0}\n",
    "for key in list(index['чендлер'].keys()):\n",
    "    for i in range(8):\n",
    "        if key.startswith('Friends - '+str(i)):\n",
    "            fr_ch[i]+=index['чендлер'][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fr_ch[1] = fr_ch[1]/19\n",
    "fr_ch[2] = fr_ch[2]/24\n",
    "fr_ch[3] = fr_ch[3]/21\n",
    "fr_ch[4] = fr_ch[4]/25\n",
    "fr_ch[5] = fr_ch[5]/25\n",
    "fr_ch[6] = fr_ch[6]/26\n",
    "fr_ch[7] = fr_ch[7]/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 3.0,\n",
       " 2: 2.1666666666666665,\n",
       " 3: 3.6666666666666665,\n",
       " 4: 4.16,\n",
       " 5: 5.52,\n",
       " 6: 5.769230769230769,\n",
       " 7: 5.76}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый популярный сезон у Чендлера - 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_m = {1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0}\n",
    "for key in list(index['моника'].keys()):\n",
    "    for i in range(8):\n",
    "        if key.startswith('Friends - '+str(i)):\n",
    "            fr_m[i]+=index['моника'][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_m[1] = fr_m[1]/19\n",
    "fr_m[2] = fr_m[2]/24\n",
    "fr_m[3] = fr_m[3]/21\n",
    "fr_m[4] = fr_m[4]/25\n",
    "fr_m[5] = fr_m[5]/25\n",
    "fr_m[6] = fr_m[6]/26\n",
    "fr_m[7] = fr_m[7]/25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я подумала что будет честно разделить на количество серий в сезоне, т.к. больше серий = больше упоминаний, и это не чистая \"популярность\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 3.0,\n",
       " 2: 3.25,\n",
       " 3: 3.2857142857142856,\n",
       " 4: 2.88,\n",
       " 5: 5.12,\n",
       " 6: 4.730769230769231,\n",
       " 7: 6.08}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого, самый популярный сезон Моники - седьмой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'джоуи': 681,\n",
       " 'моника': 679,\n",
       " 'росс': 1013,\n",
       " 'рэйчел': 236,\n",
       " 'фиби': 574,\n",
       " 'чендлер': 722}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friends = ['моника', 'росс', 'джоуи', 'чендлер', 'фиби', 'рэйчел']\n",
    "freq = {}\n",
    "\n",
    "for friend in friends:\n",
    "    freq[friend] = sum(index[friend].values())\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выходит, что самый популярный - Росс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция ранжирования Okapi BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обратного индекса есть общепринятая формула для ранжирования *Okapi best match 25* ([Okapi BM25](https://ru.wikipedia.org/wiki/Okapi_BM25)).    \n",
    "Пусть дан запрос $Q$, содержащий слова  $q_1, ... , q_n$, тогда функция BM25 даёт следующую оценку релевантности документа $D$ запросу $Q$:\n",
    "\n",
    "$$ score(D, Q) = \\sum_{i}^{n} \\text{IDF}(q_i)*\\frac{(k_1+1)*f(q_i,D)}{f(q_i,D)+k_1(1-b+b\\frac{|D|}{avgdl})} $$ \n",
    "где   \n",
    ">$f(q_i,D)$ - частота слова $q_i$ в документе $D$ (TF)       \n",
    "$|D|$ - длина документа (количество слов в нём)   \n",
    "*avgdl* — средняя длина документа в коллекции    \n",
    "$k_1$ и $b$ — свободные коэффициенты, обычно их выбирают как $k_1$=2.0 и $b$=0.75   \n",
    "$$$$\n",
    "$\\text{IDF}(q_i)$ есть обратная документная частота (IDF) слова $q_i$: \n",
    "$$\\text{IDF}(q_i) = \\log\\frac{N-n(q_i)+0.5}{n(q_i)+0.5},$$\n",
    ">> где $N$ - общее количество документов в коллекции   \n",
    "$n(q_i)$ — количество документов, содержащих $q_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### реализуйте эту функцию ранжирования \n",
    "import math\n",
    "from math import log\n",
    "\n",
    "k1 = 2.0\n",
    "b = 0.75\n",
    "\n",
    "def score_BM25(qf, dl, avgdl, k1, b, N, n) -> float:\n",
    "    \"\"\"\n",
    "    Compute similarity score between search query and documents from collection\n",
    "    :return: score\n",
    "    \"\"\"\n",
    "    score = math.log((N-n+0.5)/(n+0.5)) * (k1+1)*qf/(qf+k1*(1-b+b*(dl/avgdl)))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача__:    \n",
    "напишите функцию, которая сортирует поисковую выдачу для любого входящего запроса согласно метрике *Okapi BM25*.    \n",
    "Выведите 10 первых результатов и их скор по запросу **рождественские каникулы**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def compute_sim(word, index, files_len):\n",
    "    \"\"\"\n",
    "    Compute similarity score between search query and documents from collection\n",
    "    :return: score\n",
    "    \"\"\"\n",
    "    N = len(files_len)\n",
    "    avgdl = sum(files_len.values())/N\n",
    "    if word in index:\n",
    "        n = len(index[word])\n",
    "        result = {}\n",
    "        for file in index[word]:\n",
    "            qf = index[word][file]\n",
    "            score = score_BM25(qf, files_len[file], avgdl, k1, b, N, n)\n",
    "            result[file] = score\n",
    "        return result\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "\n",
    "def get_search_result(inquiry):\n",
    "    \"\"\"\n",
    "    Compute sim score between search query and all documents in collection\n",
    "    :return: list of files\n",
    "    \"\"\"\n",
    "    global index, files_len\n",
    "    score = defaultdict(int)\n",
    "    words = preprocessing(inquiry)\n",
    "    for word in words:\n",
    "        result = compute_sim(word, index, files_len)\n",
    "        for file in result:\n",
    "            score[file] += result[file]\n",
    "    return sorted(score.items(), key=operator.itemgetter(1), reverse = True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Friends - 7x10 - The One With The Holiday Armadillo.ru.txt',\n",
       "  9.776309773280323),\n",
       " (\"Friends - 6x19 - The One With Joey's Fridge.ru.txt\", 7.831350385518332),\n",
       " ('Friends - 3x10 - The One Where Rachel Quits.ru.txt', 5.6005292157657385),\n",
       " (\"Friends - 2x09 - The One With Phoebe's Dad.ru.txt\", 4.787759807254001),\n",
       " ('Friends - 1x17 - The One With Two Parts (2).ru.txt', 4.139458794305614),\n",
       " (\"Friends - 4x03 - The One With The 'Cuffs.ru.txt\", 4.121790362729642),\n",
       " ('Friends - 1x16 - The One With Two Parts (1).ru.txt', 4.052599599125035),\n",
       " ('Friends - 4x10 - The One With The Girl From Poughkeepsie.ru.txt',\n",
       "  4.02648492884397),\n",
       " ('Friends - 6x12 - The One With The Joke.ru.txt', 3.4614800887510877),\n",
       " ('Friends - 6x09 - The One Where Ross Got High.ru.txt', 3.4162272692841538)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "get_search_result('рождественские каникулы')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
